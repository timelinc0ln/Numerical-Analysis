{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple iteration for systems of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate a random diagonally dominant matrix, for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rndm = np.random.RandomState(1234)\n",
    "\n",
    "n = 10\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.  Jacobi iteration\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "\n",
    "separate the diagonal part $D$,\n",
    "\n",
    "$$ A = D + (A - D) $$\n",
    "\n",
    "and write\n",
    "\n",
    "$$\n",
    "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
    "$$\n",
    "\n",
    "Then iterate\n",
    "\n",
    "$$\n",
    "x_{n + 1} = B x_{n} + c\\;,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_1d = np.diag(A)\n",
    "\n",
    "B = -A.copy()\n",
    "np.fill_diagonal(B, 0)\n",
    "\n",
    "D = np.diag(diag_1d)\n",
    "invD = np.diag(1./diag_1d)\n",
    "BB = invD @ B \n",
    "c = invD @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "assert_allclose(-B + D, A)\n",
    "\n",
    "\n",
    "# xx is a \"ground truth\" solution, compute it using a direct method\n",
    "xx = np.linalg.solve(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@xx, b)\n",
    "np.testing.assert_allclose(D@xx, B@xx + b)\n",
    "np.testing.assert_allclose(xx, BB@xx + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that $\\| B\\| \\leqslant 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36436161983015336"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "\n",
    "x0 = np.ones(n)\n",
    "x = x0\n",
    "for _ in range(n_iter):\n",
    "    x = BB @ x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  2.22044605e-16,  0.00000000e+00, -1.11022302e-16,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.22044605e-16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result:\n",
    "\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task I.1\n",
    "\n",
    "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
    "\n",
    "\n",
    "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
    "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
    "\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  2.22044605e-16,  0.00000000e+00, -1.11022302e-16,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.22044605e-16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jacobi(A, b, niter = 50, eps = 1e-5):\n",
    "    \n",
    "    diag_1d = np.diag(A)\n",
    "    B = -A.copy()\n",
    "    np.fill_diagonal(B, 0)\n",
    "    D = np.diag(diag_1d)\n",
    "    invD = np.diag(1./diag_1d)\n",
    "    BB = invD @ B \n",
    "    c = invD @ b\n",
    "    n = 10\n",
    "    x0 = np.ones(n)\n",
    "    x = x0\n",
    "    for _ in range(niter):\n",
    "        x = BB @ x + c\n",
    "    return x\n",
    "\n",
    "x = jacobi(A,b)\n",
    "print(x)\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 0.3566914437228362\n",
      "Difference betweeen computed and actual: [-6.93889390e-18  0.00000000e+00  6.93889390e-18  0.00000000e+00\n",
      "  0.00000000e+00 -4.33680869e-19 -4.33680869e-19  1.04083409e-17\n",
      "  0.00000000e+00 -1.38777878e-17]\n",
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 0.5932879674772259\n",
      "Difference betweeen computed and actual: [5.55111512e-17 7.63278329e-17 4.16333634e-17 8.32667268e-17\n",
      " 5.55111512e-17 6.24500451e-17 4.68375339e-17 7.63278329e-17\n",
      " 7.63278329e-17 6.93889390e-17]\n",
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 0.966109731961311\n",
      "Difference betweeen computed and actual: [1.26186969e-06 1.88531294e-06 1.50905278e-06 7.15806424e-07\n",
      " 8.97706760e-07 1.65875038e-06 1.09916692e-06 1.23539831e-06\n",
      " 1.25398736e-06 1.70210746e-06]\n",
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 1.3320597672329353\n",
      "Difference betweeen computed and actual: [420.36591585 361.75325045 414.57030781 415.74316825 335.71129024\n",
      " 471.78605159 401.46764147 366.68889488 395.52748855 351.38544852]\n",
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 1.5084206651048684\n",
      "Difference betweeen computed and actual: [125687.30514587 124977.23040205 153958.50063443 177051.13362546\n",
      " 160517.04314296 127098.62334525 164343.00994111 183615.54886445\n",
      " 115994.08173112 167556.15558927]\n",
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 1.9402174565229526\n",
      "Difference betweeen computed and actual: [1.01849591e+10 1.68678577e+10 1.36112771e+10 1.30775243e+10\n",
      " 1.73713311e+10 1.93444646e+10 1.24119467e+10 1.66737380e+10\n",
      " 1.75887148e+10 9.55739301e+09]\n",
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 2.2360842954064655\n",
      "Difference betweeen computed and actual: [6.23090137e+12 7.08339557e+12 7.49085619e+12 8.67871706e+12\n",
      " 1.00530407e+13 9.06296349e+12 7.59958691e+12 7.68952851e+12\n",
      " 6.92552730e+12 3.53470292e+12]\n",
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 2.2724018025081065\n",
      "Difference betweeen computed and actual: [1.81270162e+13 1.96532481e+13 1.27726482e+13 1.16528278e+13\n",
      " 8.45746630e+12 1.41155863e+13 2.18129984e+13 1.53534226e+13\n",
      " 1.46857889e+13 1.85972087e+13]\n",
      "x by Jacobi: [ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "Normal of B: 2.6159568112628655\n",
      "Difference betweeen computed and actual: [4.31163976e+16 3.75321965e+16 3.46226812e+16 4.68683264e+16\n",
      " 3.66137077e+16 3.23453196e+16 4.15227262e+16 4.02491928e+16\n",
      " 4.93270873e+16 5.80376387e+16]\n"
     ]
    }
   ],
   "source": [
    "# Now make the elements of A \"smaller\"\n",
    "def jacobi_mod(A, b, niter = 50, eps = 1e-5):\n",
    "    '''Same inputs, but implementation, but returns different items for comparison\n",
    "        Compute the Jacobi iteration\n",
    "        Compute the normal of B\n",
    "        Compute the actual solution using package solutions and return the difference.\n",
    "        Returns:\n",
    "        x: the solved matrix\n",
    "        normB: the normal of the B matrix\n",
    "        xx: the solution by numpypackages, used for the difference'''\n",
    "    diag_1d = np.diag(A)\n",
    "    B = -A.copy()\n",
    "    np.fill_diagonal(B, 0)\n",
    "    D = np.diag(diag_1d)\n",
    "    invD = np.diag(1./diag_1d)\n",
    "    BB = invD @ B \n",
    "    # added normal computation\n",
    "    normB = np.linalg.norm(BB)\n",
    "    c = invD @ b\n",
    "    n = 10\n",
    "    x0 = np.ones(n)\n",
    "    x = x0\n",
    "    for _ in range(niter):\n",
    "        x = BB @ x + c\n",
    "    xx = np.linalg.solve(A, b)\n",
    "    return x, normB, (x - xx)\n",
    "for i in range(1,10):\n",
    "    # make the elements of A smaller with each iteration\n",
    "    A1 = rndm.uniform(size=(n, n)) + np.diagflat([15/i]*(n))\n",
    "    x1, normB, x2 = jacobi_mod(A1,b)\n",
    "    print(\"x by Jacobi:\", x)\n",
    "    print(\"Normal of B:\", normB)\n",
    "    print(\"Difference betweeen computed and actual:\", x2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Seidel's iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task II.1\n",
    "\n",
    "Implement the Seidel's iteration. \n",
    "\n",
    "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  1.11022302e-16,  1.11022302e-16,  0.00000000e+00,\n",
       "       -1.11022302e-16,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "        2.77555756e-17,  1.11022302e-16])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seidels(A, b, niter = 50, eps = 1e-05):\n",
    "    x = np.ones(b.shape[0])\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        for k in range(b.shape[0]):\n",
    "              x[k] = (b[k]- (A[k][:k] @ x[:k]) - (A[k][k+1:] @ x[k+1:])) / A[k,k]\n",
    "    return x\n",
    "\n",
    "x = seidels(A, b)\n",
    "print(x)\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Minimum residual scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task III.1\n",
    "\n",
    "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
    "\n",
    "(50% of the grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n",
      "[ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n",
      " -0.00577279  0.03177549 -0.00422849  0.05284648]\n"
     ]
    }
   ],
   "source": [
    "def minres(A, b, niter = 50):\n",
    "    x = np.ones(b.shape[0])\n",
    "    for i in range(niter):\n",
    "        r = A @ x - b\n",
    "        k = (r @ A @ r) / np.linalg.norm(A @ r)**2\n",
    "        x = x - k * r     \n",
    "    return x\n",
    "\n",
    "x = minres(A, b)\n",
    "x1 = np.linalg.solve(A, b)\n",
    "print(x)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
