{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. One-sided finite differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, `deriv`, which computes a derivative of its argument at a given point, $x$, using a one-sided finite difference rule with a given step side $h$, with the approximation order of $O(h^2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(f, x, h):\n",
    "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
    "    \n",
    "    Compute the derivative using the one-sided rule of the approximation order of $O(h^2)$.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        The function to differentiate\n",
    "    x : float\n",
    "        The point to compute the derivative at.\n",
    "    h : float\n",
    "        The step size for the finite different rule.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fder : derivative of f(x) at point x using the step size h.\n",
    "    \"\"\"\n",
    "    x1 = x + h\n",
    "    dx = x1 - x\n",
    "    df = f(x1) - f(x)\n",
    "    fder = df / dx\n",
    "    return fder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test I.1\n",
    "\n",
    "Test your function on a simple test case: differentiate $f(x) = x^3$ at $x=0$. Comment on whether your results are consistent with the expected value of $f'(x) = 0$ and on an expected scaling with $h\\to 0$.\n",
    "\n",
    " (10% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 --  0.0001\n",
      "0.001000 --   1e-06\n",
      "0.000100 --   1e-08\n",
      "0.000010 --   1e-10\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(lambda x: x**3, x, h)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are consistent with what we'd expect for h approaching 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.2\n",
    "\n",
    "Now use a slightly more complicated function, $f(x) = x^2 \\log{x}$, evaluate the derivative at $x=1$ using your one-sided rule and a two-point one-sided rule. Roughly estimate the value of $h$ where the error stops decreasing, for these two schemes. \n",
    "(15% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def f(x):\n",
    "    return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    return x * (2.*log(x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual  1.0\n",
      "h value:  0.01\n",
      "Computed:  1.0150332503316761\n",
      "Error:  -0.015033250331676129\n",
      "h value:  0.001\n",
      "Computed:  1.0015003332500332\n",
      "Error:  -0.0015003332500331812\n",
      "h value:  0.0001\n",
      "Computed:  1.00015000333325\n",
      "Error:  -0.00015000333324999282\n",
      "h value:  1e-05\n",
      "Computed:  1.0000150000333332\n",
      "Error:  -1.5000033333212315e-05\n",
      "h value:  1e-06\n",
      "Computed:  1.0000015000003333\n",
      "Error:  -1.5000003332765743e-06\n",
      "h value:  1e-07\n",
      "Computed:  1.0000001500000033\n",
      "Error:  -1.5000000330722685e-07\n",
      "h value:  1e-08\n",
      "Computed:  1.000000015\n",
      "Error:  -1.4999999908837935e-08\n",
      "h value:  1e-09\n",
      "Computed:  1.0000000015000001\n",
      "Error:  -1.5000001241105565e-09\n",
      "h value:  1e-10\n",
      "Computed:  1.00000000015\n",
      "Error:  -1.5000001241105565e-10\n",
      "h value:  1e-11\n",
      "Computed:  1.000000000015\n",
      "Error:  -1.5000001241105565e-11\n",
      "h value:  1e-12\n",
      "Computed:  1.0000000000015001\n",
      "Error:  -1.5001333508735115e-12\n",
      "h value:  1e-13\n",
      "Computed:  1.0000000000001499\n",
      "Error:  -1.4988010832439613e-13\n",
      "h value:  1e-14\n",
      "Computed:  1.000000000000015\n",
      "Error:  -1.509903313490213e-14\n",
      "h value:  1e-15\n",
      "Computed:  1.0000000000000016\n",
      "Error:  -1.5543122344752192e-15\n"
     ]
    }
   ],
   "source": [
    "def deriv2pt(f, x, h):\n",
    "    x1 = x + h\n",
    "    dx = x1 - x\n",
    "    df = f(x1) - f(x)\n",
    "    fder = df / dx\n",
    "    return fder\n",
    "\n",
    "print(\"Actual \", actual)\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]:\n",
    "    err = deriv(f, 1, h)\n",
    "    actual = fder(1)\n",
    "    print(\"h value: \", h)\n",
    "    print(\"Computed: \", err)\n",
    "    print(\"Error: \", actual - err)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.3 \n",
    "\n",
    "Now try differentiating $x^2 \\log(x)$ at $x=0$. Use the three-point one-sided rule. Note that to evaluate the function at zero, you need to special-case this value. Check the scaling of the error with $h$, explain your results. \n",
    "(25% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 -- -0.04605\n",
      "0.001000 -- -0.006908\n",
      "0.000100 -- -0.000921\n",
      "0.000010 -- -0.0001151\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x == 0:\n",
    "        # the limit of $x^2 log(x)$ at $x-> 0$ is zero, even though log(x) is undefined at x=0\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x*(2*log(x) + 1)\n",
    "\n",
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(f, x, h) - fder(x)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error decreases as expected as the value of h approaches zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Midpoint rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which computes a definite integral using the midpoint rule up to a given error, $\\epsilon$. Estimate the error by comparing the estimates of the integral at $N$ and $2N$ elementary intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "b = 5\n",
    "a = 0\n",
    "N = 5\n",
    "h = (b - a) / N\n",
    "x_list = [a + 0.5 * h + n * h for n in range(N)]\n",
    "\n",
    "def midpoint_rule(func, a, b, eps):\n",
    "    \"\"\" Calculate the integral of f from a to b using the midpoint rule.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        The function to integrate.\n",
    "    a : float\n",
    "        The lower limit of integration.\n",
    "    b : float\n",
    "        The upper limit of integration.\n",
    "    eps : float\n",
    "        The target accuracy of the estimate.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    integral : float\n",
    "        The estimate of $\\int_a^b f(x) dx$.\n",
    "    \"\"\"\n",
    "    N = 1\n",
    "    h = (b-a) / N\n",
    "    x_list = [a + 0.5 * h + n * h for n in range(N)]\n",
    "    y_list = np.array([func(x) for x in x_list])\n",
    "    new_est = h * np.sum(y_list)\n",
    "    old_est = new_est + 1e5\n",
    "    while(np.abs(new_est-old_est)>eps):\n",
    "        N = N * 2\n",
    "        h = (b - a) / N\n",
    "        x_list = [a + 0.5 * h + n * h for n in range(N)]\n",
    "        y_list = np.array([func(x) for x in x_list])\n",
    "        old_est = new_est\n",
    "        new_est = h * np.sum(y_list)\n",
    "    return new_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.1\n",
    "\n",
    "Test your midpoint rule on a simple integral, which you can calculate by paper and pencil.\n",
    "\n",
    "Compare the rate of convergence to the expected $O(N^{-2})$ scaling by studying the number of intervals required for a given accuracy $\\epsilon$.\n",
    "\n",
    "Compare the numerical results to the value you calculated by hand. Does the deviation agree with your estimate of the numerical error?\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions as intended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.33333206176758"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f2(x):\n",
    "    return x**2\n",
    "\n",
    "midpoint_rule(f2, 1, 5, eps=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.2\n",
    "\n",
    "Now use your midpoint rule to compute the value of\n",
    "\n",
    "$$\n",
    "\\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x}\\, dx\n",
    "$$\n",
    "\n",
    "up to a predefined accuracy of $\\epsilon=10^{-4}$.\n",
    "\n",
    "Note that the integral contains an integrable singularity at the lower limit. Do calculations two ways: first, do a straightforward computation; next, subtract the singularity. Compare the number of iterations required to achieve the accuracy of $\\epsilon$.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return np.sin(np.sqrt(x)) / x\n",
    "\n",
    "def f3(x):\n",
    "    return f2(x) - 1 / np.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10788699436045195"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midpoint_rule(f3, 0, 1, eps=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
